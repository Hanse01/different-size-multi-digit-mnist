{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LHpsBAnlsU2"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from imageio import imwrite\n",
        "import argparse\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "mnist_keys = ['train-images-idx3-ubyte', 'train-labels-idx1-ubyte',\n",
        "              't10k-images-idx3-ubyte', 't10k-labels-idx1-ubyte']\n",
        "\n",
        "\n",
        "def check_mnist_dir(data_dir):\n",
        "\n",
        "    downloaded = np.all([osp.isfile(osp.join(data_dir, key)) for key in mnist_keys])\n",
        "    if not downloaded:\n",
        "        if not os.path.exists(data_dir):\n",
        "            os.makedirs(data_dir)\n",
        "        download_mnist(data_dir)\n",
        "    else:\n",
        "        print('MNIST was found')\n",
        "\n",
        "\n",
        "def download_mnist(data_dir):\n",
        "\n",
        "    data_url = 'http://yann.lecun.com/exdb/mnist/'\n",
        "    for k in mnist_keys:\n",
        "        k += '.gz'\n",
        "        url = (data_url+k).format(**locals())\n",
        "        target_path = os.path.join(data_dir, k)\n",
        "        cmd = ['curl', url, '-o', target_path]\n",
        "        print('Downloading ', k)\n",
        "        subprocess.call(cmd)\n",
        "        cmd = ['gunzip', '-d', target_path]\n",
        "        print('Unzip ', k)\n",
        "        subprocess.call(cmd)\n",
        "\n",
        "\n",
        "def extract_mnist(data_dir):\n",
        "\n",
        "    num_mnist_train = 60000\n",
        "    num_mnist_test = 10000\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 'train-images-idx3-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    train_image = loaded[16:].reshape((num_mnist_train, 28, 28, 1))\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 'train-labels-idx1-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    train_label = np.asarray(loaded[8:].reshape((num_mnist_train)))\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 't10k-images-idx3-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    test_image = loaded[16:].reshape((num_mnist_test, 28, 28, 1))\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 't10k-labels-idx1-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    test_label = np.asarray(loaded[8:].reshape((num_mnist_test)))\n",
        "\n",
        "    return np.concatenate((train_image, test_image)), \\\n",
        "        np.concatenate((train_label, test_label))\n",
        "    \n",
        "def extract_mnist2(data_dir):\n",
        "\n",
        "    num_mnist_train = 60000\n",
        "    num_mnist_test = 10000\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 'train-images-idx3-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    train_image = loaded[16:].reshape((num_mnist_train, 28, 28, 1))\n",
        "    train_image1 = []\n",
        "    for i in range(60000):\n",
        "      im = cv2.resize(train_image[i],(88, 88))\n",
        "      train_image1.append(im)\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 'train-labels-idx1-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    train_label1 = np.asarray(loaded[8:].reshape((num_mnist_train)))\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 't10k-images-idx3-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    test_image = loaded[16:].reshape((num_mnist_test, 28, 28, 1))\n",
        "    test_image1 = []\n",
        "    for i in range(10000):\n",
        "      im1 = cv2.resize(test_image[i],(88, 88))\n",
        "      test_image1.append(im1)\n",
        "\n",
        "    fd = open(os.path.join(data_dir, 't10k-labels-idx1-ubyte'))\n",
        "    loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
        "    test_label1 = np.asarray(loaded[8:].reshape((num_mnist_test)))\n",
        "\n",
        "    return np.concatenate((train_image1, test_image1)), \\\n",
        "        np.concatenate((train_label1, test_label1))        \n",
        "\n",
        "def sample_coordinate(high, size):\n",
        "    if high > 0:\n",
        "        return np.random.randint(high, size=size)\n",
        "    else:\n",
        "        return np.zeros(size).astype(np.int)\n",
        "\n",
        "\n",
        "def generator(config):\n",
        "    # check if mnist is downloaded. if not, download it\n",
        "    check_mnist_dir(config.mnist_path)\n",
        "\n",
        "    # extract mnist images and labels\n",
        "    image, label = extract_mnist(config.mnist_path)\n",
        "    h, w = image.shape[1:3]\n",
        "\n",
        "    image2, label2 = extract_mnist2(config.mnist_path)\n",
        "    h2, w2 = image2.shape[1:3]\n",
        "    \n",
        "\n",
        "    # split: train, val, test\n",
        "    rs = np.random.RandomState(config.random_seed)\n",
        "    num_original_class = len(np.unique(label))\n",
        "    num_class = len(np.unique(label))**config.num_digit\n",
        "    classes = list(np.array(range(num_class)))\n",
        "    rs.shuffle(classes)\n",
        "    num_train, num_val, num_test = [\n",
        "            int(float(ratio)/np.sum(config.train_val_test_ratio)*num_class)\n",
        "            for ratio in config.train_val_test_ratio]\n",
        "    train_classes = classes[:num_train]\n",
        "    val_classes = classes[num_train:num_train+num_val]\n",
        "    test_classes = classes[num_train+num_val:]\n",
        "\n",
        "    # label index\n",
        "    indexes = []\n",
        "    for c in range(num_original_class):\n",
        "        indexes.append(list(np.where(label == c)[0]))\n",
        "\n",
        "    # generate images for every class\n",
        "    assert config.image_size[1]//config.num_digit >= w\n",
        "    np.random.seed(config.random_seed)\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    split_classes = [train_classes, val_classes, test_classes]\n",
        "    count = 1\n",
        "    for i, split_name in enumerate(['train', 'val', 'test']):\n",
        "        path = osp.join(data_dir, split_name)\n",
        "        print('Generat images for {} at {}'.format(split_name, path))\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        for j, current_class in enumerate(split_classes[i]):\n",
        "            class_str = str(current_class)\n",
        "            class_str = '0'*(config.num_digit-len(class_str))+class_str\n",
        "            class_path = osp.join(path, class_str)\n",
        "            print('{} (progress: {}/{})'.format(class_path, count, len(classes)))\n",
        "            if not os.path.exists(class_path):\n",
        "                os.makedirs(class_path)\n",
        "            for k in range(700):\n",
        "              # sample images\n",
        "              digits = [int(class_str[l]) for l in range(config.num_digit)]\n",
        "              imgs = [np.squeeze(image[np.random.choice(indexes[d])]) for d in digits]\n",
        "              background = np.zeros((config.image_size)).astype(np.uint8)\n",
        "            # sample coordinates\n",
        "              ys = sample_coordinate(config.image_size[0]-h, config.num_digit)\n",
        "              xs = sample_coordinate(config.image_size[1]//config.num_digit-w,\n",
        "                                       size=config.num_digit)\n",
        "              xs = [l*config.image_size[1]//config.num_digit+xs[l]\n",
        "                      for l in range(config.num_digit)]\n",
        "                # combine images\n",
        "           \n",
        "              background[ys[0]:ys[0]+h, xs[0]:xs[0]+w] = imgs[0]\n",
        "                # write the image\n",
        "\n",
        "\n",
        "              digits1 = [int(class_str[l]) for l in range(config.num_digit)]\n",
        "              imgs1 = [np.squeeze(image2[np.random.choice(indexes[d])]) for d in digits1]\n",
        "            \n",
        "            # sample coordinates\n",
        "              ys1 = sample_coordinate(config.image_size[0]-h2, config.num_digit)\n",
        "              xs1 = sample_coordinate(config.image_size[1]//config.num_digit-w2,\n",
        "                                       size=config.num_digit)\n",
        "              xs1 = [l*config.image_size[1]//config.num_digit+xs1[l]\n",
        "                      for l in range(config.num_digit)]\n",
        "                # combine images\n",
        "            \n",
        "              background[ys1[1]:ys1[1]+h2, xs1[1]:xs1[1]+w2] = imgs1[1]\n",
        "              background = cv2.resize(background, (112, 112))\n",
        "                # write the image\n",
        "              image_path = osp.join(class_path, '{}_{}.png'.format(k, class_str))\n",
        "                # image_path = osp.join(config.multimnist_path, '{}_{}_{}.png'.format(split_name, k, class_str))\n",
        "              imwrite(image_path, background)\n",
        "              \n",
        "            count += 1\n",
        "\n",
        "    return image, label, indexes\n",
        "\n",
        "\n",
        "def argparser():\n",
        "\n",
        "    def str2bool(v):\n",
        "        return v.lower() == 'true'\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "    parser.add_argument('--mnist_path', type=str, default='./datasets/mnist/',\n",
        "                        help='path to *.gz files')\n",
        "    parser.add_argument('--multimnist_path', type=str, default='./datasets/multimnist')\n",
        "    parser.add_argument('--num_digit', type=int, default=2)\n",
        "    parser.add_argument('--train_val_test_ratio', type=int, nargs='+',\n",
        "                        default=[64, 16, 20], help='percentage')\n",
        "    parser.add_argument('--image_size', type=int, nargs='+',\n",
        "                        default=[196, 196])\n",
        "    parser.add_argument('--num_image_per_class', type=int, default=10000)\n",
        "    parser.add_argument('--random_seed', type=int, default=11)\n",
        "    config = parser.parse_args(args=[])\n",
        "    return config\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    config = argparser()\n",
        "    assert len(config.train_val_test_ratio) == 3\n",
        "    assert sum(config.train_val_test_ratio) == 100\n",
        "    assert len(config.image_size) == 2\n",
        "    generator(config)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}